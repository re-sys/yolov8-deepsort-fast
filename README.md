添加了使用openvino部署，并且缩小了deep模型中的特征提取
时间分析：
1:  640x640 12 persons, 1 bench, 52.9ms
    Speed: 8.1ms preprocess, 52.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
    Time taken for _get_features: 0.04415 seconds
    大致上yolo模型耗时52.9ms，特征提取耗时44.15ms，后处理耗时1.4ms，总耗时54.3ms，速度约为98ms/image。

2.  640x640 16 persons, 3 bicycles, 1 motorcycle, 1 potted plant, 53.1ms
    Speed: 7.5ms preprocess, 53.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)
    Time taken for tracker.predict: 0.00053 seconds
    Time taken for tracker.update: 0.00177 seconds

3.  已经尝试在cpp上搭建相同的模型，检测模型相比python调用的检测内容更加不准确，有的人物没办法探测到，具体原因不清楚。
    同时也搭载了自己设置的deepsort的特征提取模型，但是检测效果不够，这个模型也没有办法很好的实施。也已经尝试采用openvino样式也
    使用特征提取模型，但是没能找到部署方式，有待进一步研究。

4.  在测试视频中，发现有的行人追踪后出现丢失，于是采取多种方案补救。
    方案一：增大新出现的行人检测阈值，就是使得新tracker的检测阈值更高（3->5），这样可以更好的追踪到过去的未被检测到的行人。
    实际效果：没有明显的效果，丢失的人物仍然会丢失。
    方案二：希望匹配的阈值更低（0.5——>0.3），方便重新最终匹配。
    实际效果：没有明显的效果，丢失的人物仍然会丢失。
    方案三：增加检测的置信度阈值，使得行人检测更加严格。
    实际效果：成功解决了丢失的问题，可以追踪到所有行人。

5.  中间遇到巨大的安装软件问题，导致无法安装openvino，想办法找资料安装，最终六个小时才完成配置
    但是安装成功后，在测试视频中，检测效果不如预期，cpp并没有给模型大幅度优化，而且还出现更差的检测精度。
    于是决定放弃cpp部署，转而使用python部署，完成后续的工作。

现在的工作问题：
1.  小车上没有办法固定好相机并且不会影响到雷达的代价地图生成。
    尝试解决方案：
        1. 把相机放在底下，但是这样必须非常远才能看到人的全身，不然只能看到膝盖以下
        2. 尝试把movebase，或者雷达的有效检测距离调小，从而近距离的干扰不会作为信息点而生成膨胀
        3. 尝试将人物必须有足够高的confidence才作为目标，还有暂时不用跟踪，因为时延太高，人物的晃动很难追踪到，暂时就一个人追踪即可
        4. 对于这个人的距离，不应该只使用中心点的深度信息，这样会导致如果中心点在两腿之间，他会认为人在对面墙壁那里
        5. 现在cv2无法显示图像进行调试，这大大增加了开发的难度。但是在单独得文件中，不适用ros是可以的
        
2.